# ğŸ§  Cyberbullying Comment Classifier

A **machine learning project** designed to detect and classify **cyberbullying comments** across social media posts using **TF-IDF features** and two optimized models â€” **Logistic Regression** and **Random Forest**.  
Built with a focus on **speed, interpretability, and real-world usability**.

---

## ğŸŒ Project Overview

Cyberbullying remains a major concern in digital communication.  
This project demonstrates a **text classification pipeline** that can automatically categorize online comments into specific bullying types such as **age, gender, religion, ethnicity**, and more.

The dataset used combines:
- `cyberbullying_tweets.csv`
- `cyberbullying_dataset.csv`

Both merged and cleaned for balanced representation.

---

## ğŸ“Š Exploratory Data Analysis

<p align="center">
  <img src="images/eda_dark.png" width="85%" alt="EDA Visualization">
</p>

---

## âš™ï¸ Model Architecture

Text preprocessing â†’ TF-IDF Vectorization â†’ Dual Model Comparison

- **Model 1:** Logistic Regression (fast, interpretable baseline)  
- **Model 2:** Random Forest (non-linear, ensemble approach)

<p align="center">
  <img src="images/model_dark.png" width="85%" alt="Model Workflow Diagram">
</p>

---

## ğŸ“ˆ Model Performance

| Model | Accuracy | Strengths |
|:------|:----------|:-----------|
| Logistic Regression | **64.73%** | Fast training and good generalization |
| Random Forest | **58.07%** | Better on complex relations, but slower |

<p align="center">
  <img src="images/confusion_dark.png" width="80%" alt="Confusion Matrix Visualization">
</p>

---

## ğŸ§ª Key Observations

- **Logistic Regression** performed best overall (65% accuracy).
- **Random Forest** struggled with unbalanced labels but showed strong recall in a few minority classes.
- Text normalization and stopword removal were critical to improving accuracy.

---

## ğŸ“ Project Structure

â”œâ”€â”€ artifacts/
â”‚ â”œâ”€â”€ LogisticRegression_fast.joblib
â”‚ â”œâ”€â”€ RandomForest_fast.joblib
â”‚ â””â”€â”€ vectorizer_fast.joblib
â”œâ”€â”€ images/
â”‚ â”œâ”€â”€ eda_dark.png
â”‚ â”œâ”€â”€ model_dark.png
â”‚ â””â”€â”€ confusion_dark.png
â”œâ”€â”€ cyberbullying_tweets.csv
â”œâ”€â”€ cyberbullying_dataset.csv
â”œâ”€â”€ generate_images_and_readme.py
â”œâ”€â”€ main_pipeline.py
â””â”€â”€ README.md


---

## ğŸ§© Tech Stack

- **Python 3.x**
- **Pandas**, **NumPy**, **Scikit-learn**
- **Matplotlib / Seaborn**
- **NLTK**
- **Joblib**

---

## ğŸš€ Usage

To run the main pipeline:

```bash
python main_pipeline.py
Or, to regenerate visuals and update documentation:

bash
Copy code
python generate_images_and_readme.py
Outputs:

artifacts/ â†’ trained models

images/ â†’ visualization set

README.md â†’ updated project summary

ğŸ§  Author
Mayuri Motwani
B.Tech, Computer Science Engineering â€” Data Science Lab
âœ¨ Passionate about AI, NLP, and social good applications

ğŸ Summary
This project is a foundational NLP experiment in social media analysis and automated moderation.

Future extensions include:

BERT or LSTM-based text embeddings

Real-time Streamlit dashboard

Bias and fairness analysis in language models

vbnet
Copy code

